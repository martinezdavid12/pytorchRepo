{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Pytorch Version: \" + torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar tensor\n",
    "scalar = torch.tensor(7)\n",
    "scalar\n",
    "\n",
    "scalar.ndim #dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.7000])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Vector \n",
    "vector = torch.tensor([7.7])\n",
    "print(vector)\n",
    "print(vector.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#MATRIX\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "print(MATRIX)\n",
    "print(MATRIX.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 1],\n",
      "         [1, 1, 0],\n",
      "         [1, 1, 2]]])\n",
      "3\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "#TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 1],\n",
    "                       [1, 1, 0],\n",
    "                       [1, 1, 2]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 7])\n",
      "tensor([[0.2970, 0.7513, 0.4894, 0.1067, 0.2661, 0.1986, 0.5087],\n",
      "        [0.1936, 0.4431, 0.6121, 0.3399, 0.8969, 0.7082, 0.0395],\n",
      "        [0.5143, 0.7273, 0.1270, 0.9565, 0.0248, 0.8383, 0.1274]])\n"
     ]
    }
   ],
   "source": [
    "#Random Tensor\n",
    "#Create a random tensor\n",
    "\n",
    "#provide size\n",
    "random_tensor = torch.rand(3, 7)\n",
    "print(random_tensor.ndim)\n",
    "print(random_tensor.shape)\n",
    "print(random_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random tensor with similar shape to image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height, width, color channels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Random Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneTensor = torch.ones(size=(3,4))\n",
    "oneTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "nineRange = torch.arange(0,10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creatign Zeros-like\n",
    "ten_zeros = torch.zeros_like(input=nineRange)\n",
    "ten_zeros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Flot 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                                dtype=None, # Data type\n",
    "                                device=\"cpu\", # What device is your tensor on\n",
    "                                requires_grad=False) # Whether or not to track gradients with tensor\n",
    "float_32_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)  # Casting to lower precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9., 36., 81.])\n"
     ]
    }
   ],
   "source": [
    "#Multiplication accorss data types?\n",
    "print(float_32_tensor * float_16_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.long)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from Tensors\n",
    "\n",
    "1. Tensors not right Data Type\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on right device - For local AMD GPU machine, just use \"cpu\"  use \"cuda\" if NVIDIA Gpu used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 6, 9])\n",
      "Datatype of tensor:  torch.Size([3])\n",
      "Device tensor is on:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(int_32_tensor)\n",
    "print(f\"Datatype of tensor:  {int_32_tensor.shape}\")\n",
    "print(f\"Device tensor is on:  {int_32_tensor.device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating and Operating with tensors\n",
    "\n",
    "Tensor Operations: \n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matric Mulitplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor 1\n",
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor1 + 10  # adds 10 to each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiplication:    WORKS ELEMENT WISE\n",
    "tensor1 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 - 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Two main ways of performing multiplication in machine learning and deep learning\n",
    "1. Matrix Multiplication (dot product)\n",
    "2. Element Wise multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "EqualsL tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element Wise: \n",
    "print(tensor1, \"*\", tensor1)\n",
    "print(f\"EqualsL {tensor1 * tensor1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) dot tensor([1, 2, 3])\n",
      "tensor(42)\n",
      "Wall time: 1e+03 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix Multiplication:  (DOT PRODUCT)\n",
    "print(tensor1, \"dot\", tensor1)\n",
    "print(torch.matmul(tensor1, int_32_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 22,  7],\n",
       "        [ 6, 66, 21],\n",
       "        [ 2, 50, 14]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensors\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                        [3, 6],\n",
    "                        [8, 2]])\n",
    "tensor_B = torch.tensor([[0, 1],\n",
    "                        [4, 9],\n",
    "                        [1, 3]])\n",
    "#torch.mm is analagous to matmul\n",
    "#torch.matmul(tensor_A, tensor_B)\n",
    "tensor_BT = tensor_B.T\n",
    "print(tensor_BT.shape)\n",
    "\n",
    "# To fix shape issues, use transpose!\n",
    "torch.matmul(tensor_A, tensor_BT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.0000,  3.5000,  6.0000,  8.5000, 11.0000, 13.5000, 16.0000, 18.5000,\n",
       "         21.0000, 23.5000, 26.0000, 28.5000, 31.0000, 33.5000, 36.0000, 38.5000,\n",
       "         41.0000, 43.5000, 46.0000, 48.5000, 51.0000, 53.5000, 56.0000, 58.5000,\n",
       "         61.0000, 63.5000, 66.0000, 68.5000, 71.0000, 73.5000, 76.0000, 78.5000,\n",
       "         81.0000, 83.5000, 86.0000, 88.5000, 91.0000, 93.5000, 96.0000, 98.5000]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1,100,2.5)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: tensor(1.)\n",
      "Min: tensor(98.5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.0000,  3.5000,  6.0000,  8.5000, 11.0000, 13.5000, 16.0000, 18.5000,\n",
       "         21.0000, 23.5000, 26.0000, 28.5000, 31.0000, 33.5000, 36.0000, 38.5000,\n",
       "         41.0000, 43.5000, 46.0000, 48.5000, 51.0000, 53.5000, 56.0000, 58.5000,\n",
       "         61.0000, 63.5000, 66.0000, 68.5000, 71.0000, 73.5000, 76.0000, 78.5000,\n",
       "         81.0000, 83.5000, 86.0000, 88.5000, 91.0000, 93.5000, 96.0000, 98.5000]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the min and max\n",
    "print(\"Min: \" + str(torch.min(x)))\n",
    "print(\"Min: \" + str(torch.max(x)))\n",
    "x, x.dtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.7500)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find Mean - torch.mean() function will require a tensor of float32 datatype!\n",
    "torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  3.5000,  6.0000,  8.5000, 11.0000, 13.5000, 16.0000, 18.5000,\n",
       "        21.0000, 23.5000, 26.0000, 28.5000, 31.0000, 33.5000, 36.0000, 38.5000,\n",
       "        41.0000, 43.5000, 46.0000, 48.5000, 51.0000, 53.5000, 56.0000, 58.5000,\n",
       "        61.0000, 63.5000, 66.0000, 68.5000, 71.0000, 73.5000, 76.0000, 78.5000,\n",
       "        81.0000, 83.5000, 86.0000, 88.5000, 91.0000, 93.5000, 96.0000, 98.5000])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reuse tensor x\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finds position in tensor with minimal value with argmin() -> returns index position\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(39)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finds position in tensor with minimal value with argmin() -> returns index position\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(98.5000)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x.argmax()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as original tensor\n",
    "* Stacking - combine multiple tensors vstack(on top of each other) or hstack(side by side).\n",
    "* Squeeze - removes all `1` dimensions from a tensor.\n",
    "* Unsqueeze - add a `1` dimension to a target tensor.\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a particular way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#Create tensor\n",
    "import torch\n",
    "x = torch.arange(0, 10)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n",
      "torch.Size([5, 2])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "#Add an extra dimension   Stuff must add up\n",
    "x_reshaped1 = x.reshape(1,10)\n",
    "x_reshaped2 = x.reshape(5,2)\n",
    "x_reshaped3 = x.reshape(10,1)\n",
    "\n",
    "print(x_reshaped1)\n",
    "print(x_reshaped1.shape)\n",
    "print(x_reshaped2)\n",
    "print(x_reshaped2.shape)\n",
    "print(x_reshaped3)\n",
    "print(x_reshaped3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the View\n",
    "z = x.view(1, 10)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
       " tensor([4, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing z changes x (because a view of a tensor shares the same memory as the original tensor)\n",
    "z[:, 0] = 4\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [4, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [4, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [4, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stack Tensors on top of each other  (V-Stack)\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[[0.8185],\n",
      "         [0.3964]],\n",
      "\n",
      "        [[0.9152],\n",
      "         [0.8344]],\n",
      "\n",
      "        [[0.8817],\n",
      "         [0.0132]],\n",
      "\n",
      "        [[0.4247],\n",
      "         [0.4350]],\n",
      "\n",
      "        [[0.4850],\n",
      "         [0.5960]]])\n",
      "Squeezed tensor: tensor([[0.8185, 0.3964],\n",
      "        [0.9152, 0.8344],\n",
      "        [0.8817, 0.0132],\n",
      "        [0.4247, 0.4350],\n",
      "        [0.4850, 0.5960]])\n"
     ]
    }
   ],
   "source": [
    "#Squeeze:    torch.squeese() - removes all 1 dimensions from a target tensor\n",
    "# 1 dimension containers act like removable containers .... sort of ...\n",
    "tn = torch.rand(size=(5,2,1))\n",
    "tnSqueezed = torch.squeeze(tn)   # removes \"1\" dimensions.\n",
    "print(f\"Previous tensor: {tn}\")\n",
    "print(f\"Squeezed tensor: {tnSqueezed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target tensor: tensor([[0.8185, 0.3964],\n",
      "        [0.9152, 0.8344],\n",
      "        [0.8817, 0.0132],\n",
      "        [0.4247, 0.4350],\n",
      "        [0.4850, 0.5960]])\n",
      "Previous shape: torch.Size([5, 2])\n",
      "\n",
      " New UNSQUEEZED tensor: tensor([[[0.8185],\n",
      "         [0.3964]],\n",
      "\n",
      "        [[0.9152],\n",
      "         [0.8344]],\n",
      "\n",
      "        [[0.8817],\n",
      "         [0.0132]],\n",
      "\n",
      "        [[0.4247],\n",
      "         [0.4350]],\n",
      "\n",
      "        [[0.4850],\n",
      "         [0.5960]]])\n",
      "New (original tn shape) shape: torch.Size([5, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#torch.unsqueeze()  -  adds a single dimension to a target tensor at a specific dim (dimension)\n",
    "print(f\"Previous target tensor: {tnSqueezed}\")\n",
    "print(f\"Previous shape: {tnSqueezed.shape}\")\n",
    "\n",
    "# Add an additional dimension with unsqueeze\n",
    "# torch.unsqueeze(TARGET_TENSOR, DIMENSION TO \"WRAP\" WITH SINGLE DIMENSION)\n",
    "tnUnsqueezed = torch.unsqueeze(tnSqueezed, 2)\n",
    "print(f\"\\n New UNSQUEEZED tensor: {tnUnsqueezed}\")\n",
    "print(f\"New (original tn shape) shape: {tnUnsqueezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.1906e-01, 4.0610e-01, 9.0105e-01],\n",
       "         [8.0206e-01, 1.1850e-01, 5.7680e-01],\n",
       "         [2.1473e-01, 8.8326e-01, 3.9759e-01],\n",
       "         ...,\n",
       "         [2.6059e-01, 5.6435e-02, 6.8631e-01],\n",
       "         [7.3182e-01, 8.0589e-01, 6.7250e-01],\n",
       "         [4.3772e-01, 1.7333e-01, 7.1856e-01]],\n",
       "\n",
       "        [[9.1602e-02, 3.9481e-01, 4.0269e-01],\n",
       "         [8.9518e-01, 6.5881e-01, 3.0708e-02],\n",
       "         [9.7853e-01, 9.4710e-01, 2.4458e-01],\n",
       "         ...,\n",
       "         [6.9098e-01, 8.1801e-01, 1.1460e-03],\n",
       "         [5.8473e-01, 2.9705e-01, 6.7049e-01],\n",
       "         [4.3270e-01, 9.5215e-01, 4.2599e-01]],\n",
       "\n",
       "        [[5.4933e-01, 4.9004e-01, 7.2240e-01],\n",
       "         [4.0232e-01, 9.2364e-01, 5.3077e-01],\n",
       "         [3.8115e-01, 4.3802e-01, 6.7846e-01],\n",
       "         ...,\n",
       "         [8.6409e-01, 5.2914e-01, 1.8092e-01],\n",
       "         [7.6402e-01, 9.8428e-01, 5.6620e-01],\n",
       "         [6.9923e-01, 9.2798e-01, 3.0902e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.2902e-01, 1.6096e-02, 4.4225e-01],\n",
       "         [7.7782e-01, 2.4841e-02, 9.8647e-01],\n",
       "         [5.2442e-02, 1.8361e-01, 1.2658e-01],\n",
       "         ...,\n",
       "         [6.0789e-01, 9.0957e-01, 5.5661e-01],\n",
       "         [5.7582e-01, 8.0519e-01, 8.5638e-01],\n",
       "         [6.0183e-01, 9.5058e-01, 9.5836e-01]],\n",
       "\n",
       "        [[5.9865e-01, 2.8517e-01, 5.1993e-01],\n",
       "         [1.0165e-01, 9.2828e-02, 6.2899e-01],\n",
       "         [8.4895e-02, 9.6501e-01, 9.5496e-01],\n",
       "         ...,\n",
       "         [4.7011e-02, 4.2745e-01, 9.4921e-01],\n",
       "         [8.1031e-01, 5.7365e-01, 1.3319e-01],\n",
       "         [6.3744e-01, 4.0541e-01, 1.1667e-01]],\n",
       "\n",
       "        [[8.5932e-04, 6.1925e-01, 1.9711e-01],\n",
       "         [1.4490e-01, 4.1763e-02, 3.2447e-01],\n",
       "         [6.6241e-02, 9.8716e-01, 9.8527e-01],\n",
       "         ...,\n",
       "         [2.9079e-01, 5.8911e-02, 7.6092e-01],\n",
       "         [2.8691e-01, 3.4422e-02, 9.3529e-02],\n",
       "         [2.1188e-02, 3.9995e-01, 8.9320e-01]]])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.permute()  - Returns a view of the original tensor `input` with its dimensions permuted\n",
    "v = torch.rand(size=(224,224,3))   # good way to represent images  224 x 224 x RGB\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev shape: torch.Size([224, 224, 3])\n",
      "permuted shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# permute the original rensor to rearrange the axis or dim order\n",
    "vPermuted = v.permute(2,0,1)  # Shifts axis 0->1, 1->2, 2->0  \n",
    "print(\"prev shape: \" + str(v.shape))\n",
    "print(\"permuted shape: \" + str(vPermuted.shape))\n",
    "# [R/G/B, height, width]    3 sheets, each of RGorB insterad of 224x224 pixles of RGB data\n",
    "\n",
    "# BOTH WILL SHARE THE SAME PLACE IN MEMORY DESPITE BEING DIFFERENT VIEWS!\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "Indexing with Pytorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's index ton the new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's index on the middle bracket (dim = 1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's index on the most inner bracket (last dimension)\n",
    "x[0][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all values of 0th and 1st diensions by only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all vlaues of 2nd dimension.\n",
    "x[0,0,:]   #Get's all remaining values in last dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Tensors vs Numpy data\n",
    "Numpy is popular for scientific python things.\n",
    "PyTorch can work with it!\n",
    "* Data in NumPy, want in PyTorch - > `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> Numpy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.]\n",
      "tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "print(array)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the value of array, what will hapen to `tensor`?\n",
    "array = array + 1   #Only array will be chagned, new tensor will not change!\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor to NumPy Array\n",
    "tensor = torch.ones(23)\n",
    "numpyTensor = tensor.numpy()\n",
    "tensor, numpyTensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducility (trying to take random out of Random)\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of random seed.\n",
    "\"Psuedorandomness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3260, 0.2897, 0.3466],\n",
       "        [0.6945, 0.6382, 0.8429],\n",
       "        [0.0186, 0.4801, 0.1666]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#Create two random tensors\n",
    "randomTensorA = torch.rand(4,3)\n",
    "randomTensorB = torch.rand(4,3)\n",
    "print(randomTensorA == randomTensorB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True],\n",
      "        [True, True],\n",
      "        [True, True],\n",
      "        [True, True],\n",
      "        [True, True],\n",
      "        [True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Create random, yet reproducible tensors\n",
    "import torch\n",
    "#First, set a random SEED\n",
    "RANDOM_SEED = 231\n",
    "torch.manual_seed(RANDOM_SEED)   # MANUAL SEED WILL GENERALLY WORK FOR ONE\n",
    "randomTensorC = torch.rand(7,2)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "randomTensorD = torch.rand(7,2)\n",
    "print(randomTensorC == randomTensorD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Tensors and Pytorch objexts on the GPUs (and making faster computations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU:\n",
    "1. Use google colab\n",
    "2. Local\n",
    "3. Cloud computing setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK FOR GPU in COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chekc for GPU access with PyTorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup device agnostic code (i.e use GPU if possible)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tensor = torch.tensor([1,2,3])\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count number of devices?\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), device(type='cpu'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Move tensor to GPU (if available)\n",
    "tensor_on_target = tensor.to(device)\n",
    "tensor_on_target, tensor_on_target.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving tensors back to the CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If tensor is on GPU, can't trandorm it to NumpPy\n",
    "# To fixc the GPU tensor with NumPy issue, we can first set it to the CPU\n",
    "tensorOnCpu = tensor.to(device=\"cpu\")\n",
    "tensor.numpy()   # able to convert tensor to numpy data when it is computed by the CPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0de8dca92e58d953bd0b4c4a24f2f9c9fc6c7fad76695c4c09fbdc6bb1767a07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
